{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "attention modelで文書分類\n",
    "# 未完成\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy\n",
    "from argparse import ArgumentParser\n",
    "from chainer import Chain, Variable, cuda, functions, links, optimizer, optimizers, serializers\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "#import util.generators as gens\n",
    "#from util.functions import trace, fill_batch\n",
    "#from util.vocabulary import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Added comment\n",
    "\n",
    "def make_corpus(list_corpus, lower_freq=1):\n",
    "    list_all_word = [word for row in list_corpus for word in row]\n",
    "    list_word_freq = collections.Counter(list_all_word)\n",
    "    # 頻度がlower_freq以下の単語を<unk>に変える\n",
    "    list_unk_word = [word for word, freq in list_word_freq.items() if freq <= lower_freq]\n",
    "    list_corpus_rev = [['<s>']+['<unk>' if word in list_unk_word else word for word in row]+['</s>'] for row in list_corpus]\n",
    "    # 辞書を作成\n",
    "    dict_word_id = {'<s>': 0, '</s>':1, '<unk>':2}\n",
    "    for row in list_corpus_rev:\n",
    "        counter = 3\n",
    "        for word in row:\n",
    "            if word not in dict_word_id:\n",
    "                dict_word_id[word] = counter\n",
    "                counter += 1\n",
    "    # 作成した辞書を用いて、corpus中の単語をidに変更\n",
    "    list_corpus_id = [[dict_word_id[word] for word in row] for row in list_corpus_rev]\n",
    "    # 作成したコーパスと辞書を返す\n",
    "    return list_corpus_id, dict_word_id\n",
    "\n",
    "class SrcEmbed(Chain):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super(SrcEmbed, self).__init__(\n",
    "            xe = links.EmbedID(vocab_size, embed_size),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return functions.tanh(self.xe(x))\n",
    "\n",
    "\n",
    "class LSTMEncoder(Chain):\n",
    "    def __init__(self, embed_size, hidden_size):\n",
    "        super(LSTMEncoder, self).__init__(\n",
    "            lstm = links.LSTM(embed_size, hidden_size),\n",
    "        )\n",
    "    def reset(self):\n",
    "        self.zerograds()\n",
    "    def __call__(self, x):\n",
    "        h = self.lstm(x)\n",
    "        return h\n",
    "\n",
    "class Attention(Chain):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__(\n",
    "            pw = links.Linear(hidden_size, hidden_size),\n",
    "            we = links.Linear(hidden_size, 1),\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, a_list):\n",
    "        e_list = []\n",
    "        self.empha = []\n",
    "        sum_e = Variable(np.array([[0]], dtype='float32'))\n",
    "        for a in a_list:\n",
    "            w = functions.tanh(self.pw(a))\n",
    "            e = functions.exp(self.we(w))\n",
    "            e_list.append(e)\n",
    "            sum_e += e\n",
    "\n",
    "        ZEROS = Variable(np.zeros((1, self.hidden_size), dtype='float32'))\n",
    "        aa = ZEROS\n",
    "        for a, e in zip(a_list, e_list):\n",
    "            e /= sum_e\n",
    "            self.empha.append(e)\n",
    "            aa += a * functions.broadcast_to(e, (1, self.hidden_size))\n",
    "        #aa += functions.reshape(functions.batch_matmul(a, e), (batch_size, self.hidden_size))\n",
    "        return aa\n",
    "\n",
    "class AttentionLM(Chain):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, label_size):\n",
    "        super(AttentionLM, self).__init__(\n",
    "            emb = SrcEmbed(vocab_size, embed_size),\n",
    "            enc = LSTMEncoder(embed_size, hidden_size),\n",
    "            att = Attention(hidden_size),\n",
    "            outae = links.Linear(hidden_size, hidden_size),\n",
    "            outey = links.Linear(hidden_size, label_size),\n",
    "        )\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.label_size = label_size\n",
    "\n",
    "    def reset(self):\n",
    "        self.zerograds()\n",
    "        self.x_list = []\n",
    "        self.h_list = []\n",
    "\n",
    "    def embed(self, x):\n",
    "        self.x_list.append(self.emb(x))\n",
    "\n",
    "    def encode(self):\n",
    "        for x in self.x_list:\n",
    "            self.h = self.enc(x)\n",
    "            self.h_list.append(self.h)\n",
    "\n",
    "    def decode(self):\n",
    "        aa = self.att(self.h_list)\n",
    "        y = functions.tanh(self.outae(aa))\n",
    "        return self.outey(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(variable):\n",
    "    #return variable.data\n",
    "    return cuda.to_cpu(variable.data)\n",
    "\n",
    "def forward(list_corpus_one, label, model):\n",
    "    L = len(list_corpus_one)\n",
    "\n",
    "    opt.zero_grads()\n",
    "\n",
    "    for one in list_corpus_one:\n",
    "        model.embed(Variable(np.array([one], dtype='int32')))\n",
    "    s_t = Variable(np.array([label], dtype='int32'))\n",
    "    model.encode()\n",
    "    s_y = model.decode()\n",
    "    loss_i = functions.softmax_cross_entropy(s_y, s_t)\n",
    "    \n",
    "    return loss_i\n",
    "            \n",
    "\n",
    "def main():\n",
    "    list_corpus_id, dict_word_id = make_corpus(list_corpus, lower_freq=1)\n",
    "    list_corpus_id_y = [[row, y] for row, y in zip(list_corpus_id, list_y)]\n",
    "\n",
    "    model = AttentionLM(embed_size=300,\n",
    "                        hidden_size=100,\n",
    "                        vocab_size=len(dict_word_id),\n",
    "                        label_size=3)\n",
    "    model.reset()\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        log_ppl = 0.0\n",
    "        trained = 0\n",
    "        \n",
    "        opt = optimizers.AdaGrad(lr = 0.01)\n",
    "        opt.setup(model)\n",
    "        opt.add_hook(optimizer.GradientClipping(5))\n",
    "        # コーパスのシャッフル\n",
    "        random.shuffle(list_corpus_id_y)\n",
    "\n",
    "        for list_corpus_one, y in list_corpus_id_y:\n",
    "            loss, perplexity= forward(list_corpus_one=list_corpus_one,\n",
    "                                      label=y,\n",
    "                                      model=model)\n",
    "            loss.backward()\n",
    "            log_ppl += perplexity \n",
    "            opt.update()\n",
    "            model.reset()\n",
    "\n",
    "        serializers.save_hdf5('%s.weights'%str(epoch), model)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = AttentionLM(embed_size=10,\n",
    "                    hidden_size=5,\n",
    "                    vocab_size=20,\n",
    "                    label_size=3)\n",
    "model.reset()\n",
    "\n",
    "opt = optimizers.AdaGrad(lr = 0.01)\n",
    "opt.setup(model)\n",
    "opt.add_hook(optimizer.GradientClipping(5))\n",
    "\n",
    "for num in range(5):\n",
    "    model.embed(Variable(np.array([num], dtype='int32')))\n",
    "    \n",
    "model.encode()\n",
    "s_y = model.decode()\n",
    "\n",
    "s_t = Variable(np.array([0], dtype='int32'))\n",
    "loss_i = functions.softmax_cross_entropy(s_y, s_t)\n",
    "loss_i.backward()\n",
    "opt.update()\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = AttentionLM(embed_size=10,\n",
    "                    hidden_size=5,\n",
    "                    vocab_size=20,\n",
    "                    label_size=3)\n",
    "model.reset()\n",
    "\n",
    "opt = optimizers.Adam()\n",
    "opt.setup(model)\n",
    "opt.add_hook(optimizer.GradientClipping(5))\n",
    "\n",
    "list_corpus_one = [1,2,3,4,5]\n",
    "\n",
    "loss = forward(list_corpus_one=list_corpus_one,\n",
    "                          label=1,\n",
    "                          model=model)\n",
    "loss.backward()\n",
    "opt.update()\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.99495291e-03   4.52087075e-03   2.84918607e-03   2.08294904e-03\n",
      "   -2.49932483e-02  -9.31231957e-03  -2.92772576e-02   6.61760196e-03\n",
      "   -1.41288862e-02   1.65105797e-02]\n",
      " [  1.09188573e-03   1.17711555e-02  -1.21388007e-02  -1.05180847e-03\n",
      "   -1.15289073e-02  -1.61390249e-02  -1.75921731e-02  -1.12938248e-02\n",
      "   -2.30505075e-02   6.98590046e-03]\n",
      " [ -5.69005078e-03   1.23687144e-02   5.15864231e-03  -2.93265330e-03\n",
      "   -8.80991574e-04  -5.00305323e-04  -4.55614813e-02   2.33042948e-02\n",
      "   -1.96060650e-02   1.35435408e-03]\n",
      " [  4.80962153e-05  -5.54220984e-03   2.34324648e-03  -6.74829178e-04\n",
      "   -5.72424615e-03  -4.53865947e-03  -7.88539182e-03   3.05371289e-03\n",
      "   -6.51086541e-03   6.73896214e-03]\n",
      " [  2.44483957e-03  -7.21206982e-03   1.07384613e-03  -4.65594186e-03\n",
      "   -4.13720272e-02  -6.19655987e-03  -2.09817983e-04  -1.31178563e-02\n",
      "   -1.62142571e-02  -7.11290864e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[[ 0.00352694 -0.00120299  0.00068965  0.00082349  0.00567491]\n",
      " [ 0.00085573 -0.00029344  0.00017534  0.00019682  0.00138108]\n",
      " [-0.00852042  0.00291198 -0.0016722  -0.00201718 -0.01373395]\n",
      " [-0.0085992   0.00295596 -0.00174235 -0.00207099 -0.01392183]\n",
      " [-0.00358524  0.00122156 -0.00068221 -0.00085903 -0.00576649]]\n",
      "[[-0.01389045 -0.00952564  0.00693145  0.01971154  0.00218945]]\n",
      "[[ 0.04008159 -0.00519991 -0.0282825   0.0211904   0.01416501]\n",
      " [ 0.03368312 -0.00436982 -0.02376759  0.01780765  0.01190376]\n",
      " [ 0.07620966 -0.00988692 -0.05377531  0.04029065  0.02693282]\n",
      " [-0.04465012  0.0057926   0.03150616 -0.0236057  -0.01577954]\n",
      " [-0.02955314  0.00383402  0.02085338 -0.0156242  -0.0104442 ]]\n",
      "[[ 0.02888365 -0.05417805  0.00229791 -0.04567609  0.00601571]\n",
      " [-0.01383624  0.02595312 -0.00110077  0.02188039 -0.00288173]\n",
      " [-0.01504741  0.02822494 -0.00119713  0.02379571 -0.00313398]]\n"
     ]
    }
   ],
   "source": [
    "#print model.emb.xe.W.data\n",
    "print model.emb.xe.W.grad\n",
    "#print model.enc.lstm.c\n",
    "#print model.enc.lstm.h\n",
    "#print model.att.pw.W.data\n",
    "print model.att.pw.W.grad\n",
    "#print model.att.we.W.data\n",
    "print model.att.we.W.grad\n",
    "#print model.outae.W.data\n",
    "print model.outae.W.grad\n",
    "#print model.outey.W.data\n",
    "print model.outey.W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]]\n",
      "[[ 5.]]\n",
      "[[ 5.  5.  5.]]\n"
     ]
    },
    {
     "ename": "InvalidType",
     "evalue": "\nInvalid operation is performed in: _ * _ (Forward)\n\nExpect: in_types[0].shape == in_types[1].shape\nActual: (1, 3) != (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidType\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-7d731295b0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0my_rev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ikegamikenshin/.pyenv/versions/2.7.9/lib/python2.7/site-packages/chainer/functions/math/basic_math.pyc\u001b[0m in \u001b[0;36mmul\u001b[0;34m(lhs, rhs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# lhs * rhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0m_check_constant_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMulConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ikegamikenshin/.pyenv/versions/2.7.9/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_check_enable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ikegamikenshin/.pyenv/versions/2.7.9/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m_check_data_type_forward\u001b[0;34m(self, in_data)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m {1}\"\"\".format(self.label, str(e))\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_type_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidType\u001b[0m: \nInvalid operation is performed in: _ * _ (Forward)\n\nExpect: in_types[0].shape == in_types[1].shape\nActual: (1, 3) != (1, 1)"
     ]
    }
   ],
   "source": [
    "x = Variable(np.array([[1,2,3]], dtype='float32'))\n",
    "y = Variable(np.array([[5]], dtype='float32'))\n",
    "y_rev = functions.broadcast_to(y, (1,3))\n",
    "print x.data\n",
    "print y.data\n",
    "print y_rev.data\n",
    "z = x * y\n",
    "print z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
